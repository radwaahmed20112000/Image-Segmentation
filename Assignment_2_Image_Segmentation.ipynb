{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radwaahmed20112000/Image-Segmentation/blob/main/Assignment_2_Image_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbgsIStCbmN9"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfITkZZpVqJe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "import sys\n",
        "import math\n",
        "import scipy.io\n",
        "import cv2\n",
        "import os\n",
        "import zipfile\n",
        "import io\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_7VMrL1Vym7"
      },
      "outputs": [],
      "source": [
        "zf = zipfile.ZipFile('data_.zip')\n",
        "zf.extractall('dataSet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBCXfNI1YYsY"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/dataSet/data_/images/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0ZDubMt1U_e"
      },
      "source": [
        "Read image and create data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PohZZFyKCrP"
      },
      "outputs": [],
      "source": [
        "df = None\n",
        "df1 = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAzmFz9i_By7"
      },
      "outputs": [],
      "source": [
        "def prepare_image(image_path, bonus=False):\n",
        "\n",
        "  global df, df1\n",
        "\n",
        "  colourImg = Image.open(image_path)\n",
        "  colourPixels = colourImg.convert(\"RGB\")\n",
        "  size = colourImg.size[::-1]\n",
        "\n",
        "  colourPixels = colourPixels.resize(size, Image.ANTIALIAS)\n",
        "  colourArray = np.array(colourPixels.getdata()).reshape(size + (3,))\n",
        "\n",
        "  indicesArray = np.moveaxis(np.indices(size), 0, 2)\n",
        "  allArray = np.dstack((indicesArray, colourArray)).reshape((-1, 5))\n",
        "\n",
        "  df1 = pd.DataFrame(allArray, columns=[\"row\", \"column\", \"red\", \"green\", \"blue\"])\n",
        "  if not bonus:\n",
        "    df = df1.iloc[:,2:]\n",
        "  else:\n",
        "    df = df1\n",
        "    df['row'] = df['row'] * 0.02\n",
        "    df['column'] = df['column'] * 0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqep7TDA1Rm3"
      },
      "outputs": [],
      "source": [
        "def read_segmentations(path, i):\n",
        "  file = scipy.io.loadmat(path + \".mat\")\n",
        "\n",
        "  if len(file['groundTruth'][0]) == i:\n",
        "    return -1\n",
        "\n",
        "  segmap = file['groundTruth'][0][i][0][0][0]\n",
        "  segmap = segmap.flatten()\n",
        "\n",
        "  max_class_label = max(segmap)\n",
        "\n",
        "  df1['labels'] = segmap\n",
        "\n",
        "  return max_class_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf09JUR1bX9W"
      },
      "source": [
        "# **Ground Truth Visualisation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sk5FPuQ1apn"
      },
      "source": [
        "Plot ground truth of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJQ9ObFXiH5c"
      },
      "outputs": [],
      "source": [
        "def visualize_image(img):\n",
        "\n",
        "  file = scipy.io.loadmat(img + \".mat\")\n",
        "  image = img + \".jpg\"\n",
        "\n",
        "  segmap1 = file['groundTruth'][0][0][0][0][0]\n",
        "  segmap2 = file['groundTruth'][0][1][0][0][0]\n",
        "  segmap3= file['groundTruth'][0][2][0][0][0]\n",
        "  segmap4 = file['groundTruth'][0][3][0][0][0]\n",
        "  segmap5 = file['groundTruth'][0][4][0][0][0]\n",
        "  img2=plt.imread(image)\n",
        "\n",
        "  fig = plt.figure(figsize=(20, 40))\n",
        "    \n",
        "  rows = 6\n",
        "  columns = 3\n",
        "\n",
        "  fig.add_subplot(rows, columns, 1)\n",
        "    \n",
        "  plt.imshow(img2)\n",
        "  plt.title(\"Image\",size = 30)\n",
        "\n",
        "\n",
        "  fig.add_subplot(rows, columns, 4)\n",
        "    \n",
        "  plt.imshow(segmap1)\n",
        "  plt.title(\"Segmentation 1\",size = 20)\n",
        "\n",
        "  fig.add_subplot(rows, columns, 5)\n",
        "    \n",
        "  plt.imshow(segmap2)\n",
        "  plt.title(\"Segmentation 2\",size = 20)\n",
        "\n",
        "  fig.add_subplot(rows, columns, 6)\n",
        "    \n",
        "  plt.imshow(segmap3)\n",
        "  plt.title(\"Segmentation 3\",size = 20)\n",
        "\n",
        "  fig.add_subplot(rows, columns, 7)\n",
        "    \n",
        "  plt.imshow(segmap4)\n",
        "  plt.title(\"Segmentation 4\",size = 20)\n",
        "\n",
        "\n",
        "  fig.add_subplot(rows, columns, 8)\n",
        "    \n",
        "  plt.imshow(segmap5)\n",
        "  plt.title(\"Segmentation 5\",size = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvzbaB_-XujP"
      },
      "source": [
        "#**K_means Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If7BNdQ5hn8R"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def random_initialize(D, U):\n",
        " for i in range (U.shape[0]):\n",
        "   for j in range(U.shape[1]):\n",
        "     U[i][j] = random.uniform(D.min().min(), D.max().max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxEb53BVoWPz"
      },
      "outputs": [],
      "source": [
        "def mean_calc(C, D):\n",
        "\n",
        "  mu = np.zeros(len(D.columns))\n",
        "  for c in C:\n",
        "    row = D.iloc[c]\n",
        "    mu = mu + row\n",
        "    \n",
        "  return mu/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9eVoFYIsGFJ"
      },
      "outputs": [],
      "source": [
        "def is_convergent(U, U_new, thres):\n",
        "  for i in range(len(U)):\n",
        "    if  np.linalg.norm(U[i] - U_new[i]) > thres:\n",
        "      return False\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeNYFmIZX4-O"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "def cluster_assignment(D, U, C,labels):\n",
        "\n",
        "   distances = euclidean_distances(D, U)\n",
        "\n",
        "   for count, l in enumerate(distances):\n",
        "      cluster_number = np.argmin(l)\n",
        "      C[cluster_number].append(count)\n",
        "      labels[count] = cluster_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxEWCyk1MZCV"
      },
      "outputs": [],
      "source": [
        "def k_means(D, K, T, th = 0):\n",
        "  col = len(D.columns)\n",
        "  \n",
        "  U = np.zeros((K, col), dtype = float)\n",
        "  random_initialize(D, U)\n",
        "  clusters = []\n",
        "  \n",
        "  labels = [0] * 154401\n",
        "  \n",
        "  for t in range(T):\n",
        "    C = []\n",
        "    \n",
        "    for i in range(K):\n",
        "      C.append([])\n",
        "      \n",
        "    cluster_assignment(D, U, C,labels)\n",
        "    U_new = np.zeros((K, col), dtype = float)\n",
        "    for i in range (K):\n",
        "      U_new[i] = mean_calc(C[i], D)\n",
        "    \n",
        "    if is_convergent(U, U_new, th):\n",
        "      return C\n",
        "\n",
        "  clusters = C\n",
        "  return clusters,labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMboXYio22D5"
      },
      "source": [
        "# **Entropy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDXy_10v6vHU"
      },
      "outputs": [],
      "source": [
        "max_class_label = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBYBakFY3EmQ"
      },
      "outputs": [],
      "source": [
        "def cluster_entropy(cluster):\n",
        "\n",
        "  entropy = 0\n",
        "  n_cluster = len(cluster)\n",
        "  cluster = np.array(cluster)\n",
        "  for i in range(max_class_label + 1):\n",
        "\n",
        "    ni = cluster[cluster[:, -1] == i+1, :].shape[0]\n",
        "\n",
        "    prob = ni/n_cluster\n",
        "\n",
        "    if prob != 0:\n",
        "      entropy -= prob * math.log2(prob)\n",
        "\n",
        "  return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAKugRy83Feg"
      },
      "outputs": [],
      "source": [
        "def calculate_segmentation_entropy(clusters):\n",
        "\n",
        "  n_dataset = df.shape[0]\n",
        "  total_entropy = 0\n",
        "\n",
        "  for cluster in clusters:\n",
        "\n",
        "    if len(cluster) == 0:\n",
        "      continue\n",
        "      \n",
        "    prob = len(cluster)/n_dataset\n",
        "    \n",
        "    total_entropy += prob * cluster_entropy(cluster) \n",
        "\n",
        "  return total_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGLyYq5g6N8B"
      },
      "outputs": [],
      "source": [
        "def calculate_entropy(image_path, segmentations):\n",
        "  global max_class_label\n",
        "\n",
        "  average = 0\n",
        "\n",
        "  for i in range(5):\n",
        "  \n",
        "    # print(\"Entropy For Segmentation \" + str(i+1) + \" :\")\n",
        "  \n",
        "    max_class_label = read_segmentations(image_path, i)\n",
        "    if max_class_label == -1 : break\n",
        "  \n",
        "    entropy = calculate_segmentation_entropy(segmentations)\n",
        "    # print(entropy)\n",
        "\n",
        "    average += entropy\n",
        "  total_avg = average/5\n",
        "  print(total_avg)\n",
        "  return total_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA0ZuiU-I9XT"
      },
      "source": [
        "# **F-Measure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGY5Vz2PN172"
      },
      "outputs": [],
      "source": [
        "def get_values_of_labels(path, i):\n",
        "  file = scipy.io.loadmat(path + \".mat\")\n",
        "  if len(file['groundTruth'][0]) == i : return -1, -1\n",
        "\n",
        "  segmap = file['groundTruth'][0][i][0][0][0]\n",
        "\n",
        "  segmap = segmap.flatten()\n",
        "  unique,counts = np.unique(segmap, return_counts=True)\n",
        "  \n",
        "  return unique,counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUtvwEurOZjE"
      },
      "outputs": [],
      "source": [
        "def get_segmentation(path, i):\n",
        "  file = scipy.io.loadmat(path + \".mat\")\n",
        "\n",
        "  segmap = file['groundTruth'][0][i][0][0][0]\n",
        "  segmap = segmap.flatten()\n",
        "\n",
        "  return segmap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def change_clusters(segmentation,labels):\n",
        "\n",
        "  j = 0\n",
        "  for i in labels:\n",
        "    segmentation = np.where(segmentation == i, j, segmentation) \n",
        "    j+=1\n",
        "\n",
        "  return segmentation  "
      ],
      "metadata": {
        "id": "xdG5s-UsYadg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyU9YddsM5ez"
      },
      "outputs": [],
      "source": [
        "def prepare_for_f_measure(clusters,segmentation):\n",
        "\n",
        "  i = 0;\n",
        "  for cluster in clusters:\n",
        "    for j in range(0, len(cluster)):\n",
        "      cluster[j] = i\n",
        "    i+=1\n",
        "\n",
        "  new_clusters = []\n",
        "  for sublist in clusters:\n",
        "    for cluster in sublist:\n",
        "      new_clusters.append(cluster)\n",
        "\n",
        "  clusters = np.array(new_clusters)\n",
        "  clusters = np.vstack((clusters,segmentation))\n",
        "\n",
        "  return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOBbYLIiMuCO"
      },
      "outputs": [],
      "source": [
        "def generate_clusters_for_f_measure(clusters, labels):\n",
        "\n",
        "  true_clusters = []\n",
        "  predicted_clusters = []\n",
        "\n",
        "  for i in range(0,labels.size):\n",
        "    predicted_clusters.append([])\n",
        "    true_clusters.append([])\n",
        "\n",
        "  for i in range(0,len(clusters[0])):\n",
        "      predicted_clusters[clusters[1][i]].append(clusters[0][i])\n",
        "  \n",
        "  for i in range(0,labels.size):\n",
        "    for j in range(0, len(predicted_clusters[i])):\n",
        "      true_clusters[i].append(i)\n",
        "\n",
        "  return true_clusters,predicted_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrwqpogZJAPs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "def f_measure(true_clusters, predicted_clusters):\n",
        "\n",
        "  f = 0\n",
        "  for i in range(0,len(true_clusters)):\n",
        "    f += np.amax(fbeta_score(true_clusters[1], predicted_clusters[1], average=None, beta=0.5))\n",
        "\n",
        "  return f/len(true_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "def accuracy(unique,count,clusters):\n",
        "  elements_count = collections.Counter(clusters)\n",
        "  print(elements_count)\n",
        "  return"
      ],
      "metadata": {
        "id": "lZ7vpB-VFR2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaPE4FZYZZOf"
      },
      "source": [
        "# **Segmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtZGWk39cWXJ"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K95H7pR0-Ym"
      },
      "outputs": [],
      "source": [
        "def create_segment(clusters, D):\n",
        "  segmentations = []\n",
        "\n",
        "  for cluster in clusters:\n",
        "    segmentation = []\n",
        "\n",
        "    for c in cluster:\n",
        "      row = D.iloc[c]\n",
        "      segmentation.append(row)\n",
        "\n",
        "    segmentations.append(segmentation)\n",
        "    \n",
        "  return segmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLtH-bWl2zzr"
      },
      "outputs": [],
      "source": [
        "from pandas import *\n",
        "\n",
        "def plot_segmentations(labels, image_path):\n",
        "  im = Image.open(image_path)\n",
        "  im = im.convert('RGB')\n",
        "  \n",
        "  \n",
        "  labels = np.array(labels)\n",
        "  labels = labels.reshape((481, 321))\n",
        "\n",
        "  plt.imshow(labels)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS2a2ODFeBll"
      },
      "source": [
        "# **K-ways Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeVld7gXW7k_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from scipy.sparse import csr_matrix \n",
        "from scipy import linalg \n",
        "import scipy.sparse\n",
        "from scipy.sparse.linalg import inv \n",
        "from scipy.sparse.linalg import eigs \n",
        "from scipy.sparse import diags\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cag4cHt95BjS"
      },
      "outputs": [],
      "source": [
        "def k_ways(X, k, t):\n",
        "\n",
        "  A = kneighbors_graph(X, 5, mode='connectivity', include_self=False)\n",
        "\n",
        "  delta =np.empty(X.shape[0])\n",
        "  delta.fill(k)\n",
        "  delta = diags(delta)\n",
        " \n",
        "  \n",
        "  inv_delta = inv(delta)\n",
        "\n",
        "  L = delta - A\n",
        "  B = L.multiply(inv_delta)\n",
        "\n",
        "  eigen_values, U = eigs(B, k=k)\n",
        "  U = U.real\n",
        "\n",
        "  Y = normalize(U, norm='l1', axis=1)\n",
        "  Y = pd.DataFrame(Y)\n",
        "  \n",
        "  return k_means(Y, k, t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyexMOPxf4CU"
      },
      "outputs": [],
      "source": [
        "def cluster_data(model, data, k, t):\n",
        "  clusters ,labels = model(data, k, t)\n",
        "  return create_segment(clusters, df1),labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpqpzoov2zQr"
      },
      "source": [
        "# **Big Picture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmy_Vt_N22F4"
      },
      "outputs": [],
      "source": [
        "images = [\"12003\", \"12074\", \"15004\", \"15088\", \"16052\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhvFI9K54DG4"
      },
      "source": [
        "Select a set of five images and display their corresponding ground truth against your segmentation results using K-means at K=5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU0B5O-z25HY"
      },
      "outputs": [],
      "source": [
        "for image in images:\n",
        "  prepare_image(image + \".jpg\")\n",
        "  segmentations = cluster_data(k_means, df, 5, 2)\n",
        "  print(\"Model Segmenatations:\")\n",
        "  plot_segmentations(segmentations, image)\n",
        "  print(\"Ground Truth:\")\n",
        "  visualize_image(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTmfOj6l4P0H"
      },
      "source": [
        "Select the same five images and display their corresponding ground\n",
        "truth against your segmentation results using Normalized-cut for the 5-NN graph, at K=5. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbNQhLoc4aF4"
      },
      "outputs": [],
      "source": [
        "#SARAAAAAAAAAAAAAAAAAAAAAAAAA RUN THIS\n",
        "for image in images:\n",
        "  prepare_image(image + \".jpg\")\n",
        "  segmentations = cluster_data(k_ways, df, 5, 2)\n",
        "  print(\"Normalized Cut Segmenatations:\")\n",
        "  entropy = calculate_entropy(image, segmentations)\n",
        "  print(\"Ground Truth:\")\n",
        "  visualize_image(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RoSLrfB70Co"
      },
      "source": [
        "Select the same five images and contrast your segmentation results using Normalized-cut for the 5-NN graph, at K=5 versus using K-means at K=5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceRr_odb7-Qy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45095358-bd7b-4f2e-8a19-9453d6a9b516"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k-means Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "0.022728536162962155\n",
            "Entropy For Segmentation 2 :\n",
            "0.022728536162962155\n",
            "Entropy For Segmentation 3 :\n",
            "4.642851305939226\n",
            "Entropy For Segmentation 4 :\n",
            "0.022728536162962155\n",
            "Entropy For Segmentation 5 :\n",
            "0.029904565549490045\n",
            "0.9481882959955206\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:138: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
            "  SparseEfficiencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:208: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  'is in the CSC matrix format', SparseEfficiencyWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized-Cuts Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "1.8517122506428028\n",
            "Entropy For Segmentation 2 :\n",
            "1.8517122506428028\n",
            "Entropy For Segmentation 3 :\n",
            "1.8517122506428028\n",
            "Entropy For Segmentation 4 :\n",
            "1.8517122506428028\n",
            "Entropy For Segmentation 5 :\n",
            "1.8517122506428028\n",
            "1.8517122506428028\n",
            "k-means Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "0.0\n",
            "Entropy For Segmentation 2 :\n",
            "0.0005222669713557943\n",
            "Entropy For Segmentation 3 :\n",
            "0.0005222669713557943\n",
            "Entropy For Segmentation 4 :\n",
            "0.0\n",
            "Entropy For Segmentation 5 :\n",
            "0.0\n",
            "0.0002089067885423177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:138: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
            "  SparseEfficiencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:208: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  'is in the CSC matrix format', SparseEfficiencyWarning)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized-Cuts Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "1.192740092159276\n",
            "Entropy For Segmentation 2 :\n",
            "2.1657912013750167\n",
            "Entropy For Segmentation 3 :\n",
            "2.1657912013750167\n",
            "Entropy For Segmentation 4 :\n",
            "2.165683551948847\n",
            "Entropy For Segmentation 5 :\n",
            "2.1657912013750167\n",
            "1.9711594496466347\n",
            "k-means Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "1.5405950355979479\n",
            "Entropy For Segmentation 2 :\n",
            "1.8070024758406813\n",
            "Entropy For Segmentation 3 :\n",
            "0.836443922495028\n",
            "Entropy For Segmentation 4 :\n",
            "1.7673279033072342\n",
            "Entropy For Segmentation 5 :\n",
            "1.4621676312946863\n",
            "1.4827073937071156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:138: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
            "  SparseEfficiencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:208: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  'is in the CSC matrix format', SparseEfficiencyWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized-Cuts Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "4.108838067628112\n",
            "Entropy For Segmentation 2 :\n",
            "4.108838067628112\n",
            "Entropy For Segmentation 3 :\n",
            "2.167281505047353\n",
            "Entropy For Segmentation 4 :\n",
            "4.108838067628112\n",
            "Entropy For Segmentation 5 :\n",
            "4.108838067628112\n",
            "3.7205267551119605\n",
            "k-means Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "0.24160106292971112\n",
            "Entropy For Segmentation 2 :\n",
            "0.18099873666712196\n",
            "Entropy For Segmentation 3 :\n",
            "0.27863796289658177\n",
            "Entropy For Segmentation 4 :\n",
            "0.1271633209617461\n",
            "Entropy For Segmentation 5 :\n",
            "0.2094149685483987\n",
            "0.2075632104007119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:138: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
            "  SparseEfficiencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:208: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  'is in the CSC matrix format', SparseEfficiencyWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized-Cuts Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "0.47359067561790696\n",
            "Entropy For Segmentation 2 :\n",
            "0.4699124913879095\n",
            "Entropy For Segmentation 3 :\n",
            "0.47359067561790696\n",
            "Entropy For Segmentation 4 :\n",
            "0.45978143555369927\n",
            "Entropy For Segmentation 5 :\n",
            "0.47359067561790696\n",
            "0.4700931907590659\n",
            "k-means Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "0.04821198356493735\n",
            "Entropy For Segmentation 2 :\n",
            "0.02885880706214397\n",
            "Entropy For Segmentation 3 :\n",
            "0.01745115914721027\n",
            "Entropy For Segmentation 4 :\n",
            "0.010118610155292718\n",
            "Entropy For Segmentation 5 :\n",
            "0.021982147070198684\n",
            "0.025324541399956595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:138: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
            "  SparseEfficiencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:208: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
            "  'is in the CSC matrix format', SparseEfficiencyWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized-Cuts Segmenatations:\n",
            "Entropy For Segmentation 1 :\n",
            "1.7260806972279037\n",
            "Entropy For Segmentation 2 :\n",
            "1.7260806972279037\n",
            "Entropy For Segmentation 3 :\n",
            "1.7260806972279037\n",
            "Entropy For Segmentation 4 :\n",
            "1.0602716832352443\n",
            "Entropy For Segmentation 5 :\n",
            "1.7260806972279037\n",
            "1.592918894429372\n"
          ]
        }
      ],
      "source": [
        "for image in images:\n",
        "  prepare_image(image + \".jpg\")\n",
        "  segmentations, labels = cluster_data(k_means, df, 5, 2)\n",
        "  print(\"k-means Segmenatations:\")\n",
        "  entropy = calculate_entropy(image, segmentations)\n",
        "  segmentations, labels = cluster_data(k_ways, df, 5, 2)\n",
        "  print(\"Normalized-Cuts Segmenatations:\")\n",
        "  entropy = calculate_entropy(image, segmentations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBGjvJKgGruv"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "for image in images:\n",
        "  prepare_image(image + \".jpg\")\n",
        "  segmentations = cluster_data(k_means, df, 5, 2)\n",
        "  print(\"k-means Segmenatations:\")\n",
        "  plot_segmentations(segmentations, image)\n",
        "\n",
        "  clustering = SpectralClustering(n_clusters=5, n_neighbors=5,\n",
        "      random_state=0).fit(df)\n",
        "  segementations = create_segment(clustering, df1)\n",
        "  plot_segmentations(segmentations, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PGehZLiPCAK"
      },
      "source": [
        "# **Testing to Get The Best K (50 Images)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrguxaALPYsp"
      },
      "outputs": [],
      "source": [
        "def train(folder):\n",
        "\n",
        "  count = [0, 0, 0, 0, 0]\n",
        "  ks = [3, 5, 7, 9, 11]\n",
        "  l = 0\n",
        "  entropy_average = [0, 0, 0, 0, 0]\n",
        "  f_measure_average = [0, 0, 0, 0, 0]\n",
        "  for filename in os.listdir(folder):\n",
        "    print(\"Image \" + filename)\n",
        "    l += 1\n",
        "    image = folder + filename\n",
        "    image_mat = '/content/dataSet/data_/ground_Truth/' +  filename[:-4]\n",
        "    prepare_image(image)\n",
        "\n",
        "    k_entropys = []\n",
        "    f_measures = []\n",
        "    \n",
        "    counter = 0\n",
        "    for k in ks:\n",
        "      print(\"k = \" + str(k))\n",
        "      segmentations, labels = cluster_data(k_means, df, k, 1)\n",
        "      entropy = calculate_entropy(image_mat, segmentations)\n",
        "      print(\"Average Entropy = \" + str(entropy))\n",
        "      k_entropys.append(entropy)\n",
        "\n",
        "      average = 0\n",
        "      for i in range(5):\n",
        "        # print(\"F-Score For Segmentation \" + str(i+1) + \" :\")\n",
        "        unique, c = get_values_of_labels(image_mat, i)\n",
        "        if isinstance(c, int): break\n",
        "        seg = get_segmentation(image_mat, i)\n",
        "        seg = change_clusters(seg, unique)\n",
        "        clusters = prepare_for_f_measure(segmentations, seg)\n",
        "\n",
        "        true_clusters,predicted_clusters = generate_clusters_for_f_measure(clusters, unique)\n",
        "      \n",
        "        f = f_measure(true_clusters, predicted_clusters)\n",
        "        # print(f)\n",
        "        average += f\n",
        "      print(\"Average F-Measure = \" + str(average/5))\n",
        "      f_measures.append(average/5)\n",
        "      entropy_average[counter] += entropy\n",
        "      f_measure_average[counter] += average/5\n",
        "      counter += 1\n",
        "\n",
        "    \n",
        "    index_min_entropy = k_entropys.index(min(k_entropys))\n",
        "    index_max_f = f_measures.index(max(f_measures))\n",
        "    count[index_min_entropy] += 1\n",
        "    count[index_max_f] += 1\n",
        "\n",
        "  \n",
        "  index_max_count = count.index(max(count))\n",
        "  print(\"Best K = \" + str(ks[index_max_count]))\n",
        "  print(\"Average entropy for each k = [3, 5, 7, 9, 11] :\")\n",
        "  print(entropy_average/50)\n",
        "  print(\"Average F-measure for each k = [3, 5, 7, 9, 11] :\")\n",
        "  print(f_measure_average/50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YkDUiHuQFvd"
      },
      "outputs": [],
      "source": [
        "train(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWDoO-zKUz54"
      },
      "outputs": [],
      "source": [
        "prepare_image(\"353013.jpg\", bonus=True)\n",
        "segmentations = cluster_data(k_means, df, 4, 1)\n",
        "print(calculate_entropy(\"353013\", segmentations))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_image(\"353013.jpg\", bonus=False)\n",
        "segmentations, labels = cluster_data(k_means, df, 4, 1)\n",
        "print(calculate_entropy(\"353013\", segmentations))"
      ],
      "metadata": {
        "id": "veiVHrz9SjDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sHwijIGa-cR"
      },
      "source": [
        "_____________________________________________________\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good Results and Bad Results"
      ],
      "metadata": {
        "id": "fi-WfE2bMsql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "\n",
        "bad_results = [\"15004\", \"16052\", \"55067\"]\n",
        "good_results = [\"12003\", \"124084\", \"25098\"]\n",
        "\n",
        "print(\"Bad Results: \")\n",
        "# for img in bad_results:\n",
        "  \n"
      ],
      "metadata": {
        "id": "h4xilb0_MrL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PbgsIStCbmN9",
        "Zf09JUR1bX9W",
        "LvzbaB_-XujP",
        "xMboXYio22D5",
        "JA0ZuiU-I9XT",
        "NaPE4FZYZZOf",
        "qS2a2ODFeBll",
        "tpqpzoov2zQr"
      ],
      "name": "Assignment 2 - Image Segmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}